{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import scipy.io as io\n",
    "import networkx as nx\n",
    "import random\n",
    "import itertools\n",
    "import glob\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix,roc_curve,roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat, savemat\n",
    "#from fracModel import fracOrdUU\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from numpy import arange,array,ones,linalg\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import powerlaw\n",
    "import os.path\n",
    "from os import path\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculate entropy and transition probability vector\n",
    "def Entropy_MC(s,b,k,beta,gamma,st_in,bl):\n",
    "    s = s[st_in:min(st_in+bl,len(s))]\n",
    "    inv, l, n = k-b, len(s), 4**k\n",
    "    T=np.zeros((n,n))\n",
    "    count = [0]*n\n",
    "    word_list = [''.join(x) for x in itertools.product('acgt', repeat=k)]\n",
    "    wd = dict(zip(word_list, list(range(len(word_list)))))\n",
    "    uu = []\n",
    "    for i in range(k,l-b):\n",
    "        n1, n2 = wd[s[i-k:i]], wd[s[i-k+b:i+b]]\n",
    "        T[n1,n2] += 1\n",
    "        count[n1] += 1\n",
    "        \n",
    "    wo_next = [''.join(x) for x in itertools.product('acgt', repeat=b)]\n",
    "    for i in range(n):\n",
    "        wo = word_list[i]\n",
    "        for l in wo_next:\n",
    "            j = wd[wo[b:]+l]\n",
    "            T[i,j] = (T[i,j]+beta)/(count[i]+4**b*beta)\n",
    "    sum_count = np.sum(count)+4**k*gamma\n",
    "    \n",
    "    prob = [(count[i]+gamma)/sum_count for i in range(len(count))] \n",
    "    n = len(T)\n",
    "    H = 0\n",
    "    F = []\n",
    "    for i in range(n):\n",
    "        wo = word_list[i]\n",
    "        for l in wo_next:\n",
    "            j = wd[wo[b:]+l]\n",
    "            F.append(T[i,j])\n",
    "            H-=prob[i]*T[i,j]*np.log2(T[i,j])\n",
    "    return F,H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def getSeqs(filename):\n",
    "    seq_list = defaultdict(list)\n",
    "    mapseq_list = defaultdict(list)\n",
    "    mapping = {'A': 'a', 'T': 't', 'C': 'c', 'G': 'g','a': 'a', 't': 't', 'c': 'c', 'g': 'g'}\n",
    "    with open(filename) as f:\n",
    "        j = -1\n",
    "        for i, line in enumerate(f):\n",
    "            if line.startswith('>'):\n",
    "                j += 1\n",
    "            else:\n",
    "                this_line = list(line)\n",
    "                this_line = list(filter(lambda ch: ch in 'acgtACGT', this_line))\n",
    "                seq_list[j].extend(this_line)\n",
    "                mapseq_list[j] = ''.join(list(map(lambda ch: mapping[ch], seq_list[j])))\n",
    "    return mapseq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(s,b,k,beta,gamma,st_in,bl):\n",
    "    F_list = []\n",
    "    en_list=[]\n",
    "    for i in range(len(s)):\n",
    "        F_1,en = Entropy_MC(s[i],b,k,beta,gamma,st_in,bl) #Transition Probability vector\n",
    "        F = F_1  #Using Transition Probabilty vector \n",
    "        F_list.append(F)\n",
    "        en_list.append(en)\n",
    "    return F_list,en_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = [['20A'],['19A'],['20B'],['19B'],['20C']]\n",
    "V = []\n",
    "for stat in status:\n",
    "    filenames = []\n",
    "    for s in stat:\n",
    "        filenames.append('Clade_Analysis/'+s+'.fasta')\n",
    "    print(filenames)\n",
    "    sequences = []\n",
    "    for filename in filenames:\n",
    "        sequences.append(getSeqs(filename))  \n",
    "    V.append(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Clade_Analysis/V_clades.pkl','wb') as f:  \n",
    "    pickle.dump(V,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_index(b,k,ind):\n",
    "    word_list = [''.join(x) for x in itertools.product('acgt', repeat=k)]\n",
    "    wd_next = [''.join(x) for x in itertools.product('acgt', repeat=b)]\n",
    "    l = 4**b\n",
    "    rem = ind%l\n",
    "    st =' -> '+wd_next[rem]\n",
    "    num = int(ind/l)\n",
    "    st = word_list[num]+st\n",
    "    return st\n",
    "def normalize(x):\n",
    "        return (x - x.min(0)) / x.ptp(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML(b,k,V,beta,gamma,classes,st_in,bl):\n",
    "    word_list = [''.join(x) for x in itertools.product('acgt', repeat=k)]\n",
    "    wd_next = [''.join(x) for x in itertools.product('acgt', repeat=b)]\n",
    "    X = []\n",
    "    y = []\n",
    "    ct = 0\n",
    "    n = len(V)\n",
    "    G = [[] for i in range(n)]\n",
    "    \n",
    "    for seq in V:\n",
    "        for s in seq:\n",
    "            F_list,en_list = stats(s,b,k,beta,gamma,st_in,bl)\n",
    "            G[ct]+=F_list\n",
    "        print(len(G[ct]))\n",
    "        ct+=1\n",
    "    \n",
    "    \n",
    "    min_val = float('inf')\n",
    "    for i in range(n):\n",
    "        if min_val > len(G[i]):\n",
    "            min_val = len(G[i])\n",
    "    \n",
    "    \n",
    "    for i in range(n):\n",
    "        random.shuffle(G[i])\n",
    "        X+=[G[i][j] for j in range(len(G[i]))]\n",
    "        y+=[i for j in range(len(G[i]))]\n",
    "  \n",
    "    print('Length of X: {}'.format(len(X)))\n",
    "    X_original = [x_i for x_i in X]\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X_original = np.array(X_original)\n",
    "    X = preprocessing.scale(X)\n",
    "    U_X = list(X[:min_val])\n",
    "    U_y = list(y[:min_val])\n",
    "    T_X = list(X[min_val:len(G[0])])\n",
    "    T_y = list(y[min_val:len(G[0])])\n",
    "    running_sum = len(G[0])\n",
    "    for i in range(1,n):\n",
    "        U_X+=list(X[running_sum:running_sum+min_val])\n",
    "        U_y+=list(y[running_sum:running_sum+min_val])\n",
    "        T_X+=list(X[running_sum+min_val:running_sum+len(G[i])])\n",
    "        T_y+=list(y[running_sum+min_val:running_sum+len(G[i])])\n",
    "        running_sum+=len(G[i])\n",
    "    zipped_U = list(zip(U_X,U_y))\n",
    "    random.shuffle(zipped_U)\n",
    "    U_X = [x_i for x_i,_ in zipped_U]\n",
    "    U_y = [y_i for _,y_i in zipped_U]\n",
    "    zipped_T = list(zip(T_X,T_y))\n",
    "    random.shuffle(zipped_T)\n",
    "    T_X = [x_i for x_i,_ in zipped_T]\n",
    "    T_y = [y_i for _,y_i in zipped_T]\n",
    "    U_X = np.array(U_X)\n",
    "    U_y = np.array(U_y)\n",
    "    T_X = np.array(T_X)\n",
    "    T_y = np.array(T_y)\n",
    "    return U_X,U_y,X_original,T_X,T_y\n",
    "def build_model(X,y,X_original,b,k,rr,cutoff,T,y_T,f):    #Building model for feature selection\n",
    "    kf = KFold(n_splits = 4)\n",
    "    Acc = []\n",
    "    Acc_T = []\n",
    "    sc_prob_T = []\n",
    "    n = len(rr)\n",
    "    val_score = [[] for i in range(n)]\n",
    "    feat_set = set()\n",
    "    feat_set_ind = set()\n",
    "    D = {}\n",
    "    X_orig_mean = np.mean(X_original,axis = 0)\n",
    "    X_orig_std = np.std(X_original,axis = 0)\n",
    "    fig, ax = plt.subplots()\n",
    "    gg = 0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    n_dim = 4**(k+b) \n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    for train, test in kf.split(X):\n",
    "        X_train = X[train]\n",
    "        y_train = y[train]\n",
    "        X_test = X[test]\n",
    "        y_test = y[test]\n",
    "        model = XGBClassifier(max_depth=1)\n",
    "        model.fit(X_train, y_train)\n",
    "        imp_feat = model.feature_importances_\n",
    "        imp_indices = np.argsort(imp_feat)\n",
    "        for im in range(cutoff,0,1):\n",
    "            transit = conv_index(b,k,imp_indices[im])\n",
    "            D[transit]  = (round(X_orig_mean[imp_indices[im]],2),round(X_orig_std[imp_indices[im]],4))\n",
    "            feat_set.add(transit)\n",
    "            feat_set_ind.add(imp_indices[im])\n",
    "        #plt.bar(range(len(imp_feat)),imp_feat)\n",
    "        #plt.show()\n",
    "        #plt.close()\n",
    "        imp_feat.sort()\n",
    "        #feature selection and rebuilding the model using selected features\n",
    "        thresh = imp_feat[cutoff]\n",
    "        selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "        select_X_train = selection.transform(X_train)\n",
    "        #selection_model = XGBClassifier(max_depth = 1)\n",
    "        selection_model = LogisticRegression()\n",
    "        selection_model.fit(select_X_train, y_train)\n",
    "        select_X_test = selection.transform(X_test)\n",
    "        scores = selection_model.predict(select_X_test)\n",
    "        scores_prob = selection_model.predict_proba(select_X_test)\n",
    "        if len(T) > 0:\n",
    "            select_T = selection.transform(T)\n",
    "            scores_T = selection_model.predict(select_T)\n",
    "            scores_prob_T = selection_model.predict_proba(select_T)\n",
    "            Acc_T.append(accuracy_score(scores_T,y_T))\n",
    "            sc_prob_T+=list(scores_prob_T)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, scores).ravel()\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        prec.append(precision)\n",
    "        rec.append(recall)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, scores)\n",
    "        auc = round(roc_auc_score(y_test,scores),3)\n",
    "        interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(auc)\n",
    "        #ax.plot(fpr,tpr,label = 'Fold {}, AUC = {}'.format(gg,auc))\n",
    "        ctr = 0\n",
    "        for yy in y_test:\n",
    "            val_score[yy].append(scores_prob[ctr])\n",
    "            ctr+=1\n",
    "        #print(scores_prob)\n",
    "        #imp_feat_main = selection_model.feature_importances_\n",
    "        imp_feat_main = selection_model.coef_\n",
    "        \n",
    "        Acc.append(accuracy_score(scores,y_test))\n",
    "        \n",
    "        #print(\"Accuracy: {}\".format(Acc[-1]))\n",
    "        gg+=1\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = np.mean(aucs)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(mean_fpr, mean_tpr, color='b',label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),lw=2, alpha=.8)\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Chance', alpha=.8)\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,label='$\\pm$  std. dev.')\n",
    "    ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],xlabel = 'False Positive Rate',ylabel = 'True Positive Rate',title=\"Receiver operating characteristic\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    #plt.show()\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('Clade_analysis/Model_{}_{}_clades_{}_{}'.format(b,k,rr[0],rr[1]))\n",
    "    plt.close()\n",
    "    Acc = np.array(Acc)\n",
    "    val_score = np.array(val_score)\n",
    "    if len(T)> 0:\n",
    "        Acc_T = np.array(Acc_T)\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    for i in range(n):\n",
    "        probs_mean = np.mean(val_score[i],axis = 0)\n",
    "        probs_std = np.std(val_score[i],axis = 0)\n",
    "        #print('{}'.format(rr[i]))\n",
    "        f.write(str(i)+':'+str(probs_mean)+' '+str(probs_std))\n",
    "        f.write('\\n')\n",
    "        plt.bar(rr,probs_mean,yerr=probs_std, align='center', color=['red', 'green'], ecolor='black', capsize=10)\n",
    "        plt.ylabel('Probability')\n",
    "        plt.title('{} classification probability'.format(rr[i]))\n",
    "        #plt.show()\n",
    "        plt.tight_layout()\n",
    "        #plt.savefig('Clade_analysis/{}_{}_{}_clades_{}_{}.png'.format(rr[i],b,k,rr[0],rr[1]),bbox_inches = 'tight')\n",
    "        plt.close()\n",
    "        \n",
    "    \n",
    "    f.write('Precision: %0.2f +/- %0.2f' % (np.mean(prec),np.std(prec)))\n",
    "    f.write('\\n')\n",
    "    f.write('Recall: %0.2f +/- %0.2f' % (np.mean(rec),np.std(rec)))\n",
    "    f.write('\\n')\n",
    "    f.write(str(D)+'\\n')\n",
    "    f.write(str(feat_set_ind)+'\\n')\n",
    "    if len(T) > 0:\n",
    "        f.write('Results for Independent Test set: '+str(np.mean(Acc_T))+'+/-'+str(np.std(Acc_T))+'\\n')\n",
    "    return np.mean(Acc),np.std(Acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_same(b,k,V,beta,gamma):\n",
    "    word_list = [''.join(x) for x in itertools.product('acgt', repeat=k)]\n",
    "    wd_next = [''.join(x) for x in itertools.product('acgt', repeat=b)]\n",
    "    X = []\n",
    "    y = []\n",
    "    ct = 0\n",
    "    n = 2\n",
    "    G = [[] for i in range(n)]\n",
    "    UU = []\n",
    "    for seq in V:\n",
    "        for s in seq:\n",
    "            F_list,en_list = stats(s,b,k,beta,gamma)\n",
    "            UU+=F_list\n",
    "        print(len(UU))\n",
    "    lx = len(UU)\n",
    "    ux = int(lx/2)\n",
    "    random.shuffle(UU)\n",
    "    G[0]+=[UU[j] for j in range(ux)]\n",
    "    G[1]+=[UU[j] for j in range(ux,lx)] \n",
    "    print(len(G[0]))\n",
    "    print(len(G[1]))\n",
    "    min_val = float('inf')\n",
    "    for i in range(n):\n",
    "        if min_val > len(G[i]):\n",
    "            min_val = len(G[i])\n",
    "            \n",
    "    for i in range(n):\n",
    "        random.shuffle(G[i])\n",
    "        X+=[G[i][j] for j in range(len(G[i]))]\n",
    "        y+=[i for j in range(len(G[i]))]   \n",
    "    print('Length of X: {}'.format(len(X)))\n",
    "    X_original = [x_i for x_i in X]\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X_original = np.array(X_original)\n",
    "    X = preprocessing.scale(X)\n",
    "    U_X = list(X[:min_val])\n",
    "    U_y = list(y[:min_val])\n",
    "    T_X = list(X[min_val:len(G[0])])\n",
    "    T_y = list(y[min_val:len(G[0])])\n",
    "    running_sum = len(G[0])\n",
    "    for i in range(1,n):\n",
    "        U_X+=list(X[running_sum:running_sum+min_val])\n",
    "        U_y+=list(y[running_sum:running_sum+min_val])\n",
    "        T_X+=list(X[running_sum+min_val:running_sum+len(G[i])])\n",
    "        T_y+=list(y[running_sum+min_val:running_sum+len(G[i])])\n",
    "        running_sum+=len(G[i])\n",
    "    zipped_U = list(zip(U_X,U_y))\n",
    "    random.shuffle(zipped_U)\n",
    "    U_X = [x_i for x_i,_ in zipped_U]\n",
    "    U_y = [y_i for _,y_i in zipped_U]\n",
    "    zipped_T = list(zip(T_X,T_y))\n",
    "    random.shuffle(zipped_T)\n",
    "    T_X = [x_i for x_i,_ in zipped_T]\n",
    "    T_y = [y_i for _,y_i in zipped_T]\n",
    "    U_X = np.array(U_X)\n",
    "    U_y = np.array(U_y)\n",
    "    T_X = np.array(T_X)\n",
    "    T_y = np.array(T_y)\n",
    "    return U_X,U_y,X_original,T_X,T_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('Clade_Analysis/block_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('Clade_Analysis/V_clades.pkl','rb') as g:\n",
    "    V = pickle.load(g)\n",
    "l = [[1,4]]\n",
    "beta = 0.5\n",
    "gamma = 0.5\n",
    "R = len(V)\n",
    "statuses = ['20A','19A','20B','19B','20C']\n",
    "pairs = [[0,1],[0,2],[0,3],[0,4],[1,2],[1,3],[1,4],[2,3],[2,4],[3,4]]\n",
    "folder = 'Clade_Analysis/block_length'\n",
    "cutoff = -10\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "bl = 1000 #block or region length\n",
    "for val in l:\n",
    "    b,k = val[0],val[1]\n",
    "    for p_1,p_2 in pairs:\n",
    "        acc_mean = []\n",
    "        acc_std = []\n",
    "        f = open(folder+'/'+statuses[p_1]+'_vs_'+statuses[p_2]+'_k_'+str(k)+'_'+str(bl)+'.txt','w')\n",
    "        V_1 = [V[p_1],V[p_2]]\n",
    "        \n",
    "        classes = [statuses[p_1],statuses[p_2]]\n",
    "        for st_in in range(0,30000,bl):\n",
    "            X,y,X_original,T,y_T = ML(b,k,V_1,beta,gamma,classes,st_in,bl)\n",
    "            mean,std = build_model(X,y,X_original,b,k,classes,cutoff,T,y_T,f)\n",
    "            acc_mean.append(mean)\n",
    "            acc_std.append(std)\n",
    "        plt.errorbar(range(1,31),acc_mean,acc_std,marker = 's',color = 'red',capsize = 5)\n",
    "        plt.xlabel('Region')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Mutation Detection: {} and {}'.format(classes[0],classes[1]))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(folder+'/ID_Curve_{}_{}_k_{}_{}'.format(classes[0],classes[1],k,bl))\n",
    "        plt.close()\n",
    "        f.write(statuses[p_1]+' vs '+statuses[p_2]+':'+str(acc_mean)+'+/-'+str(acc_std))\n",
    "        f.close()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import scipy.io as io\n",
    "import networkx as nx\n",
    "import random\n",
    "import itertools\n",
    "import glob\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix,roc_curve,roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat, savemat\n",
    "#from fracModel import fracOrdUU\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from numpy import arange,array,ones,linalg\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import powerlaw\n",
    "import os.path\n",
    "from os import path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_generator(length):\n",
    "    s_origin= [random.choice('acgt') for _ in range(length)]\n",
    "    s_final = ''.join(s_origin)\n",
    "    return s_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savefig(name):\n",
    "    plt.savefig(name+\".svg\", bbox_inches = 'tight',dpi=600,format='svg', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculate entropy\n",
    "def Entropy_MC(s,b,k,beta,gamma,st_in,l):\n",
    "    s = s[st_in:min(st_in+l,len(s))]\n",
    "    inv, l, n = k-b, len(s), 4**k\n",
    "    T=np.zeros((n,n))\n",
    "    count = [0]*n\n",
    "    word_list = [''.join(x) for x in itertools.product('acgt', repeat=k)]\n",
    "    wd = dict(zip(word_list, list(range(len(word_list)))))\n",
    "    uu = []\n",
    "    for i in range(k,l-b):\n",
    "        n1, n2 = wd[s[i-k:i]], wd[s[i-k+b:i+b]]\n",
    "        T[n1,n2] += 1\n",
    "        count[n1] += 1\n",
    "        \n",
    "    wo_next = [''.join(x) for x in itertools.product('acgt', repeat=b)]\n",
    "    for i in range(n):\n",
    "        wo = word_list[i]\n",
    "        for l in wo_next:\n",
    "            j = wd[wo[b:]+l]\n",
    "            T[i,j] = (T[i,j]+beta)/(count[i]+4**b*beta)\n",
    "    sum_count = np.sum(count)+4**k*gamma\n",
    "    \n",
    "    prob = [(count[i]+gamma)/sum_count for i in range(len(count))] \n",
    "    n = len(T)\n",
    "    H = 0\n",
    "    F = []\n",
    "    for i in range(n):\n",
    "        wo = word_list[i]\n",
    "        for l in wo_next:\n",
    "            j = wd[wo[b:]+l]\n",
    "            F.append(T[i,j])\n",
    "            H-=prob[i]*T[i,j]*np.log2(T[i,j])\n",
    "    return T,F,H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def getSeqs(filename):\n",
    "    seq_list = defaultdict(list)\n",
    "    mapseq_list = defaultdict(list)\n",
    "    mapping = {'A': 'a', 'T': 't', 'C': 'c', 'G': 'g','a': 'a', 't': 't', 'c': 'c', 'g': 'g'}\n",
    "    with open(filename) as f:\n",
    "        j = -1\n",
    "        for i, line in enumerate(f):\n",
    "            if line.startswith('>'):\n",
    "                j += 1\n",
    "            else:\n",
    "                this_line = list(line)\n",
    "                this_line = list(filter(lambda ch: ch in 'acgtACGT', this_line))\n",
    "                seq_list[j].extend(this_line)\n",
    "                mapseq_list[j] = ''.join(list(map(lambda ch: mapping[ch], seq_list[j])))\n",
    "    return mapseq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(s,b,k,beta,gamma,st_in,l):\n",
    "    F_list = []\n",
    "    en_list=[]\n",
    "    for i in range(len(s)):\n",
    "        F_1,en = Entropy_MC(s[i],b,k,beta,gamma,st_in,l) #Transition Probability vector\n",
    "        F = F_1#+F_2  #Append TP and FD vector together\n",
    "        F_list.append(F)\n",
    "        en_list.append(en)\n",
    "    return F_list,en_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_index(b,k,ind):\n",
    "    word_list = [''.join(x) for x in itertools.product('acgt', repeat=k)]\n",
    "    wd_next = [''.join(x) for x in itertools.product('acgt', repeat=b)]\n",
    "    l = 4**b\n",
    "    rem = ind%l\n",
    "    st =' -> '+wd_next[rem]\n",
    "    num = int(ind/l)\n",
    "    st = word_list[num]+st\n",
    "    return st\n",
    "def normalize(x):\n",
    "        return (x - x.min(0)) / x.ptp(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML(b,k,V,beta,gamma,classes,st_in,l):\n",
    "    word_list = [''.join(x) for x in itertools.product('acgt', repeat=k)]\n",
    "    wd_next = [''.join(x) for x in itertools.product('acgt', repeat=b)]\n",
    "    X = []\n",
    "    y = []\n",
    "    ct = 0\n",
    "    n = len(V)\n",
    "    G = [[] for i in range(n)]\n",
    "    \n",
    "    for seq in V:\n",
    "        for s in seq:\n",
    "            F_list,en_list = stats(s,b,k,beta,gamma,st_in,l)\n",
    "            G[ct]+=F_list\n",
    "#         print(len(G[ct]))\n",
    "        ct+=1\n",
    "    \n",
    "    \n",
    "    min_val = float('inf')\n",
    "    for i in range(n):\n",
    "        if min_val > len(G[i]):\n",
    "            min_val = len(G[i])\n",
    "   \n",
    "    \n",
    "    for i in range(n):\n",
    "        random.shuffle(G[i])\n",
    "        X+=[G[i][j] for j in range(len(G[i]))]\n",
    "        y+=[i for j in range(len(G[i]))]\n",
    "  \n",
    "    X_original = [x_i for x_i in X]\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X_original = np.array(X_original)\n",
    "    X = preprocessing.scale(X)\n",
    "    U_X = list(X[:min_val])\n",
    "    U_y = list(y[:min_val])\n",
    "    T_X = list(X[min_val:len(G[0])])\n",
    "    T_y = list(y[min_val:len(G[0])])\n",
    "    running_sum = len(G[0])\n",
    "    for i in range(1,n):\n",
    "        U_X+=list(X[running_sum:running_sum+min_val])\n",
    "        U_y+=list(y[running_sum:running_sum+min_val])\n",
    "        T_X+=list(X[running_sum+min_val:running_sum+len(G[i])])\n",
    "        T_y+=list(y[running_sum+min_val:running_sum+len(G[i])])\n",
    "        running_sum+=len(G[i])\n",
    "    zipped_U = list(zip(U_X,U_y))\n",
    "    random.shuffle(zipped_U)\n",
    "    U_X = [x_i for x_i,_ in zipped_U]\n",
    "    U_y = [y_i for _,y_i in zipped_U]\n",
    "    zipped_T = list(zip(T_X,T_y))\n",
    "    random.shuffle(zipped_T)\n",
    "    T_X = [x_i for x_i,_ in zipped_T]\n",
    "    T_y = [y_i for _,y_i in zipped_T]\n",
    "    U_X = np.array(U_X)\n",
    "    U_y = np.array(U_y)\n",
    "#     print('Length of X: {}'.format(len(U_y)))\n",
    "    T_X = np.array(T_X)\n",
    "    T_y = np.array(T_y)\n",
    "    return U_X,U_y,X_original,T_X,T_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(X,y,X_original,b,k,rr,cutoff,T,y_T,f):    #Building model for feature selection\n",
    "    kf = KFold(n_splits = 4)\n",
    "    Acc = []\n",
    "    Acc_T = []\n",
    "    sc_prob_T = []\n",
    "    n = len(rr)\n",
    "    val_score = [[] for i in range(n)]\n",
    "    feat_set = set()\n",
    "    feat_set_ind = set()\n",
    "    D = {}\n",
    "    X_orig_mean = np.mean(X_original,axis = 0)\n",
    "    X_orig_std = np.std(X_original,axis = 0)\n",
    "#     fig, ax = plt.subplots()\n",
    "    gg = 0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    n_dim = 4**(k+b) \n",
    "    acc_list = []\n",
    "#     plt.rcParams.update({'font.size': 14})\n",
    "    for train, test in kf.split(X):\n",
    "        X_train = X[train]\n",
    "        y_train = y[train]\n",
    "        X_test = X[test]\n",
    "        y_test = y[test]\n",
    "        model = XGBClassifier(max_depth=1)\n",
    "        model.fit(X_train, y_train)\n",
    "        imp_feat = model.feature_importances_\n",
    "        imp_indices = np.argsort(imp_feat)\n",
    "        for im in range(cutoff,0,1):\n",
    "            transit = conv_index(b,k,imp_indices[im])\n",
    "            D[transit]  = (round(X_orig_mean[imp_indices[im]],2),round(X_orig_std[imp_indices[im]],4))\n",
    "            feat_set.add(transit)\n",
    "            feat_set_ind.add(imp_indices[im])\n",
    "        #plt.bar(range(len(imp_feat)),imp_feat)\n",
    "        #plt.show()\n",
    "        #plt.close()\n",
    "        imp_feat.sort()\n",
    "        #feature selection and rebuilding the model using selected features\n",
    "        thresh = imp_feat[cutoff]\n",
    "        selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "        select_X_train = selection.transform(X_train)\n",
    "        #selection_model = XGBClassifier(max_depth = 1)\n",
    "        selection_model = LogisticRegression()\n",
    "        selection_model.fit(select_X_train, y_train)\n",
    "        select_X_test = selection.transform(X_test)\n",
    "        scores = selection_model.predict(select_X_test)\n",
    "        scores_prob = selection_model.predict_proba(select_X_test)\n",
    "        if len(T) > 0:\n",
    "            select_T = selection.transform(T)\n",
    "            scores_T = selection_model.predict(select_T)\n",
    "            scores_prob_T = selection_model.predict_proba(select_T)\n",
    "            Acc_T.append(accuracy_score(scores_T,y_T))\n",
    "            sc_prob_T+=list(scores_prob_T)\n",
    "        ctr = 0\n",
    "        for yy in y_test:\n",
    "            val_score[yy].append(scores_prob[ctr])\n",
    "            ctr+=1\n",
    "        ctr = 0\n",
    "        val_score_dis = [0 for i in range(n)]\n",
    "        ctx = [0 for i in range(n)]\n",
    "        for yy in y_test:\n",
    "            if scores[ctr] == yy:\n",
    "                val_score_dis[yy]+=1\n",
    "            ctx[yy]+=1\n",
    "            ctr+=1\n",
    "        for yc in range(n):\n",
    "            val_score_dis[yc] = val_score_dis[yc]/ctx[yc]*100\n",
    "        acc_list.append(val_score_dis)\n",
    "        imp_feat_main = selection_model.coef_\n",
    "        \n",
    "        Acc.append(accuracy_score(scores,y_test))\n",
    "        \n",
    "        gg+=1\n",
    "    Acc = np.array(Acc)\n",
    "    val_score = np.array(val_score)\n",
    "    if len(T)> 0:\n",
    "        Acc_T = np.array(Acc_T)\n",
    "        \n",
    "    acc_list_mean = np.mean(acc_list,axis =0)\n",
    "    acc_list_std = np.std(acc_list,axis =0)\n",
    "\n",
    "    for i in range(n):\n",
    "        probs_mean = np.mean(val_score[i],axis = 0)\n",
    "        probs_std = np.std(val_score[i],axis = 0)\n",
    "        \n",
    "    return np.mean(Acc),np.std(Acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pairwise2 module\n",
    "from Bio import pairwise2\n",
    "\n",
    "# Import format_alignment method\n",
    "from Bio.pairwise2 import format_alignment\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:08<00:00,  2.49it/s]\n",
      "100%|██████████| 20/20 [00:29<00:00,  1.50s/it]\n",
      "100%|██████████| 20/20 [01:07<00:00,  3.35s/it]\n",
      "100%|██████████| 20/20 [01:58<00:00,  5.92s/it]\n",
      "100%|██████████| 20/20 [03:08<00:00,  9.43s/it]\n",
      "100%|██████████| 20/20 [04:31<00:00, 13.59s/it]\n",
      "100%|██████████| 20/20 [06:10<00:00, 18.51s/it]\n",
      "100%|██████████| 20/20 [07:59<00:00, 23.98s/it]\n",
      "100%|██████████| 20/20 [10:11<00:00, 30.56s/it]\n",
      "100%|██████████| 20/20 [12:33<00:00, 37.66s/it]\n"
     ]
    }
   ],
   "source": [
    "# lengs = [500,1000,2000,4000,8000,16000]\n",
    "lengs=[leng*1000 for leng in range(1,11)]\n",
    "\n",
    "for leng in lengs:\n",
    "    \n",
    "#     time_list1 = []\n",
    "#     time_list2 = []\n",
    "#     time_list3 = []\n",
    "    time_list4 = []\n",
    "    \n",
    "    for i in tqdm(range(20)):\n",
    "        \n",
    "        # Generate seq_list A and B\n",
    "        N = 50 # number of sequances in each pool N=100 done, 50 done, 200 not\n",
    "        mp = 5\n",
    "        p = mp/100 # mutation probability\n",
    "        m = int(leng/1000)+1 # number of mutated bases\n",
    "        \n",
    "        L_1, L_2, _, mut_dict,_ = seq_list_generator(N,leng,p,m)\n",
    "\n",
    "    # Smith-Waterman Algorithm\n",
    "        end3 = time.time()\n",
    "        alignments = pairwise2.align.localxx(L_1[25], L_2[25])\n",
    "\n",
    "        end4 = time.time()\n",
    "        time_list4.append(N*(end4-end3))\n",
    "        \n",
    "        \n",
    "#     np.save('time1_N_'+str(N)+'_p_'+str(mp)+'_l_'+str(leng), time_list1)\n",
    "#     np.save('time2_N_'+str(N)+'_p_'+str(mp)+'_l_'+str(leng), time_list2)\n",
    "#     np.save('time3_N_'+str(N)+'_p_'+str(mp)+'_l_'+str(leng), time_list3)\n",
    "    np.save('time4_N_'+str(N)+'_p_'+str(mp)+'_l_'+str(leng), time_list4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lengs = [500,1000,2000,4000,8000,16000]\n",
    "lengs=[leng*1000 for leng in range(1,11)]\n",
    "\n",
    "for leng in lengs:\n",
    "    \n",
    "    time_list1 = []\n",
    "    time_list2 = []\n",
    "    time_list3 = []\n",
    "    time_list4 = []\n",
    "    \n",
    "    for i in tqdm(range(50)):\n",
    "        # Generate seq_list A and B\n",
    "        N = 50 # number of sequances in each pool N=50 done, 100 done, 200 not\n",
    "        mp = 10\n",
    "        p = mp/100 # mutation probability\n",
    "        m = int(leng/1000)+1 # number of mutated bases\n",
    "\n",
    "        L_1, L_2, _, mut_dict,_ = seq_list_generator(N,leng,p,m)\n",
    "\n",
    "        start1 = time.time()\n",
    "\n",
    "        l = [[1,4]]\n",
    "        beta = 0.5\n",
    "        gamma = 0.5\n",
    "        cutoff = -10\n",
    "\n",
    "        V = [[L_1],[L_2]]\n",
    "        b = 1\n",
    "        k = 4\n",
    "        st_in = 0\n",
    "        \n",
    "        l = 100 # region length\n",
    "        seq_length = leng # sequence length\n",
    "        f = open('dummy.txt'.format(l),'w')\n",
    "        x = int(seq_length/l)+1\n",
    "\n",
    "        for j in range(1):\n",
    "            classes = ['L_1','L_2']\n",
    "            C = V[0]\n",
    "            D = V[1]\n",
    "            V_1 = []\n",
    "            V_1 = [C,D]\n",
    "            acc_mean = []\n",
    "            acc_std = []\n",
    "            for st_in in range(0,seq_length,l):\n",
    "                X,y,X_original,T,y_T = ML(b,k,V_1,beta,gamma,classes,st_in,l)\n",
    "                mean,std = build_model(X,y,X_original,b,k,classes,cutoff,T,y_T,f)\n",
    "                acc_mean.append(mean)\n",
    "                acc_std.append(std) \n",
    "                \n",
    "        end1 = time.time()\n",
    "        time_list1.append(end1-start1)\n",
    "\n",
    "        mt = []\n",
    "        for i in range(len(acc_mean)):\n",
    "            if acc_mean[i] > 0.6:\n",
    "                mt.append(i+1)\n",
    "\n",
    "        start2 = time.time()\n",
    "        \n",
    "#         print(mt)\n",
    "        for m in mt:\n",
    "            if m == len(acc_mean):\n",
    "                X1 = L_1[25][(m-1)*100:]\n",
    "                Y1 = L_2[25][(m-1)*100:]\n",
    "                alignments = pairwise2.align.globalxx(X1, Y1)\n",
    "\n",
    "#                 X2 = L_1[75][(m-1)*100:]\n",
    "#                 Y2 = L_2[75][(m-1)*100:]\n",
    "#                 alignments = pairwise2.align.globalxx(X2, Y2)\n",
    "\n",
    "            else:\n",
    "\n",
    "                X1 = L_1[25][(m-1)*100:m*100]\n",
    "                Y1 = L_2[25][(m-1)*100:m*100]\n",
    "                alignments = pairwise2.align.globalxx(X1, Y1)\n",
    "\n",
    "#                 X2 = L_1[75][(m-1)*100:m*100]\n",
    "#                 Y2 = L_2[75][(m-1)*100:m*100]\n",
    "#                 alignments = pairwise2.align.globalxx(X2, Y2)\n",
    "\n",
    "        end2 = time.time()\n",
    "\n",
    "        time_list2.append(start2-end1+N*(end2-start2))\n",
    "\n",
    "\n",
    "    # Needleman-Wunsch Algorithm\n",
    "\n",
    "        alignments = pairwise2.align.globalxx(L_1[25], L_2[25])\n",
    "\n",
    "        end3 = time.time()\n",
    "        time_list3.append(N*(end3-end2))\n",
    "\n",
    "    # Smith-Waterman Algorithm\n",
    "        alignments = pairwise2.align.localxx(L_1[25], L_2[25])\n",
    "\n",
    "        end4 = time.time()\n",
    "        time_list4.append(N*(end4-end3))\n",
    "        \n",
    "        \n",
    "    np.save('time1_N_'+str(N)+'_p_'+str(mp)+'_l_'+str(leng), time_list1)\n",
    "    np.save('time2_N_'+str(N)+'_p_'+str(mp)+'_l_'+str(leng), time_list2)\n",
    "    np.save('time3_N_'+str(N)+'_p_'+str(mp)+'_l_'+str(leng), time_list3)\n",
    "    np.save('time3_N_'+str(N)+'_p_'+str(mp)+'_l_'+str(leng), time_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N100 p5\n",
    "\n",
    "lengs=[leng*1000 for leng in range(1,11)]\n",
    "\n",
    "t1_mean = []\n",
    "t1_std = []\n",
    "t2_mean = []\n",
    "t2_std = []\n",
    "t3_mean = []\n",
    "t3_std = []\n",
    "for leng in lengs:\n",
    "    t1_list = np.array(np.load('time1_N_100_p_5_l_'+str(leng)+'.npy'))\n",
    "    t1_mean.append(np.mean(t1_list))\n",
    "    t1_std.append(np.std(t1_list))\n",
    "    tm_list = np.array(np.load('time2_N_100_p_5_l_'+str(leng)+'.npy'))\n",
    "    t2_list = t1_list + tm_list\n",
    "    t2_mean.append(np.mean(t2_list))\n",
    "    t2_std.append(np.std(t2_list))\n",
    "    t3_list = np.array(np.load('time3_N_100_p_5_l_'+str(leng)+'.npy'))\n",
    "    t3_mean.append(np.mean(t3_list))\n",
    "    t3_std.append(np.std(t3_list))\n",
    "    t4_list = np.array(np.load('time4_N_100_p_5_l_'+str(leng)+'.npy'))\n",
    "    t4_mean.append(np.mean(t4_list))\n",
    "    t4_std.append(np.std(t4_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim([1000,10000])\n",
    "# plt.ylim([0,750])\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "# plt.plot(lengs,t1_mean,linewidth=2)\n",
    "# plt.fill_between(lengs,np.array(t1_mean)-np.array(t1_std), np.array(t1_mean)+np.array(t1_std), alpha=0.4)\n",
    "plt.plot(lengs,t2_mean,linewidth=2,label='State Machine')\n",
    "plt.fill_between(lengs,np.array(t2_mean)-np.array(t2_std), np.array(t2_mean)+np.array(t2_std), alpha=0.4)\n",
    "plt.plot(lengs,t3_mean,linewidth=2,label='Needleman-Wunsch')\n",
    "plt.fill_between(lengs,np.array(t3_mean)-np.array(t3_std), np.array(t3_mean)+np.array(t3_std), alpha=0.4)\n",
    "plt.plot(lengs,t4_mean,linewidth=2,label='Smith-Waterman')\n",
    "plt.fill_between(lengs,np.array(t4_mean)-np.array(t4_std), np.array(t4_mean)+np.array(t4_std), alpha=0.4)\n",
    "plt.title('N=100, p=5%')\n",
    "plt.legend()\n",
    "plt.ylabel('Time/s')\n",
    "plt.xlabel('Length/nt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
